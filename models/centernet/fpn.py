import torch
import torch.nn as nn
import torch.nn.functional as F

class FPN(nn.Module):
    def __init__(self, in_channels_list, out_channels, extra_blocks=False):
        """
        Feature Pyramid Network (FPN) module.
        Based on "Feature Pyramid Networks for Object Detection" (https://arxiv.org/abs/1612.03144)

        Args:
            in_channels_list (list[int]): A list of integers representing the number of channels
                                          for each input feature map (e.g., [512, 1024, 2048] for ResNet C3, C4, C5).
            out_channels (int): The number of channels in the output feature maps of the FPN (e.g., 256).
            extra_blocks (bool): If True, add extra FPN levels (P6, P7) by applying a single
                                 convolutional layer with stride 2 on the highest FPN level (P5).
        """
        super(FPN, self).__init__()
        
        self.inner_blocks = nn.ModuleList()
        self.layer_blocks = nn.ModuleList()
        for in_channels in in_channels_list:
            # Lateral connections: 1x1 convolution to reduce channels
            self.inner_blocks.append(nn.Conv2d(in_channels, out_channels, 1))
            # Output layers: 3x3 convolution on the combined feature map
            self.layer_blocks.append(nn.Conv2d(out_channels, out_channels, 3, padding=1))
            
        self.extra_blocks = extra_blocks
        if self.extra_blocks:
            # P6 is generated by a 3x3 stride 2 conv on P5
            self.p6_conv = nn.Conv2d(out_channels, out_channels, 3, stride=2, padding=1)
            # P7 is generated by a 3x3 stride 2 conv on P6
            self.p7_conv = nn.Conv2d(out_channels, out_channels, 3, stride=2, padding=1)

        # Initialize weights
        for m in self.modules():
            if isinstance(m, nn.Conv2d):
                nn.init.kaiming_uniform_(m.weight, a=1)
                if m.bias is not None:
                    nn.init.constant_(m.bias, 0)

    def forward(self, features):
        """
        Args:
            features (dict[str, torch.Tensor]): A dictionary of feature maps from the backbone,
                                                e.g., {'C3': c3_feat, 'C4': c4_feat, 'C5': c5_feat}.
        Returns:
            dict[str, torch.Tensor]: A dictionary of FPN feature maps, e.g., {'P3': p3_feat, ...}
        """
        # Get features in order from highest resolution to lowest (C3, C4, C5)
        # Assuming features are provided as {name: tensor}
        # For ResNet50, typically C5, C4, C3 are processed in reverse order.
        # Let's explicitly get C5, C4, C3.
        c5_feat = features['C5']
        c4_feat = features['C4']
        c3_feat = features['C3']

        # Top-down pathway & lateral connections
        # P5: 1x1 conv on C5
        p5_inner = self.inner_blocks[2](c5_feat) # Assuming inner_blocks are ordered C3, C4, C5
        p5 = self.layer_blocks[2](p5_inner)

        # P4: 1x1 conv on C4 + upsampled P5_inner
        p4_inner = self.inner_blocks[1](c4_feat) + F.interpolate(p5_inner, size=c4_feat.shape[-2:], mode='nearest')
        p4 = self.layer_blocks[1](p4_inner)

        # P3: 1x1 conv on C3 + upsampled P4_inner
        p3_inner = self.inner_blocks[0](c3_feat) + F.interpolate(p4_inner, size=c3_feat.shape[-2:], mode='nearest')
        p3 = self.layer_blocks[0](p3_inner)

        out = {'P3': p3, 'P4': p4, 'P5': p5}

        if self.extra_blocks:
            # P6 is maxpool on P5 (or conv with stride 2)
            # Common in FPN: P6 = self.p6_conv(P5)
            out['P6'] = self.p6_conv(p5)
            out['P7'] = self.p7_conv(out['P6'])
            
        return out

